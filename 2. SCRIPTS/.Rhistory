Hola
1*1
1*1
1+1
require("tidyverse","pacman")
library(tidyverse)
library(pacman)
library(rvest)
library(data.table)
library(datasets)
Chunk6 <- my_htlm "https://ignaciomsarmiento.github.io/GEIH2018_sample/page6.html"
#Se procede a llamar el chunk No. 6 de la base de datos GEIH:
Chunk6 <- my_htlm ("https://ignaciomsarmiento.github.io/GEIH2018_sample/page6.html")
Chunk6 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_6.html')
class(Chunk6)
View(Chunk6)
htlm_tablr(Chunk6)
htlm_table(Chunk6)
html_table(Chunk6)
data.frame(Chunk6)
html_table(Chunk6)
my_html %>& htlm_elements(Chunk6)
my_html %>% htlm_elements(Chunk6)
my_html %>% html_elements(Chunk6)
#Se llaman los paquetes necesarios para el Scraping
library(tidyverse)
Chunk6 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_6.html')
Chunk7 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_7.html')
Chunk8 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_8.html')
Chunk10 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_9.html')
Chunk11 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_9.html')
Chunk10 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_10.html')
library(tidyverse)
library(pacman)
library(rvest)
library(data.table)
library(datasets)
library(pacman)
library(rvest)
library(data.table)
library(datasets)
#Se procede a llamar el chunk No. 6 de la base de datos GEIH, una vez inspeccionada EL cÓDIGO html:
Chunk6 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_6.html')
Chunk7 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_7.html')
Chunk8 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_8.html')
Chunk9 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_9.html')
Chunk10 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_10.html')
class(Chunk6)
View(Chunk6)
Chunk10 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_10.html')
View(Chunk6)
html_table(Chunk6,Chunk7,Chunk8,Chunk9,Chunk10)
html_table(Chunk6)
as_tible(Chunk6)
as_tibble(Chunk6)
dara <-rbind.data.frame(Chunk10,Chunk9)
html_table('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_10.html')
html_table('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_6.html')
html_table(Chunk6)
data<-rbind.data.frame(Chunk6,Chunk7)
data<-rbind.data.frame(Chunk6, Chunk7)
data <-rbind.data.frame(Chunk6, Chunk7)
html_table(Chunk7)
data.class(Chunk6)
data.frame(Chunk6)
library(writeexl)
library(writexl)
p_load(
tidyverse,
rvest,
writexl
)
p_load(
tidyverse,
rvest,
writexl
)
library(tidyverse)
library(pacman)
library(rvest)
library(data.table)
library(datasets)
library(writexl)
url <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
# almacenamiento de datos en dataframe
# los datos contienen información de la GEIH 2018 para Bogotá
data <- data.frame()
for (i in 1:10) {
url_i <- paste0(url, i, ".html")
tablas <- url_i %>%
read_html() %>%
html_table() %>% .[[1]]
data <- rbind.data.frame(data, tablas)
View(data)
View(data)
View(data)
#Al existir problema, se inspecciona el Código HTLM de la página para encontrar la el enlace que llama directamente a la tabla:
url <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
# almacenamiento de datos en dataframe
# los datos contienen información de la GEIH 2018 para Bogotá
data <- data.frame()
for (i in 1:10) {
url_i <- paste0(url, i, ".html")
tablas <- url_i %>%
read_html() %>%
html_table() %>% .[[1]]
data <- rbind.data.frame(data, tablas)
}
for (i in 1:10) {
url_i <- paste0(url, i, ".html")
tablas <- url_i %>%
read_html() %>%
html_table() %>% .[[1]]
data <- rbind.data.frame(data, tablas)
}
data <- data.frame()
for (i in 1:10) {
url_i <- paste0(url, i, ".html")
tablas <- url_i %>%
read_html() %>%
html_table() %>% .[[1]]
data <- rbind.data.frame(data, tablas)
}
data <- data.frame()
for (i in 1:10) {
url_i <- paste0(url,i,".html")
tablas <- url_i %>%
read_html() %>%
html_table() %>% .[[1]]
data <- rbind.data.frame(data, tablas)
}
#Se llaman los paquetes necesarios para el Scraping
p_load(
tidyverse,
rvest,
writexl
)
library(tidyverse)
library(pacman)
library(rvest)
library(data.table)
library(datasets)
library(writexl)
#Se procede a llamar el chunk No. 6 de la base de datos GEIH, una vez inspeccionada el Código html:
Chunk6 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_6.html')
Chunk7 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_7.html')
Chunk8 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_8.html')
Chunk9 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_9.html')
Chunk10 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_10.html')
Chunk6 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_6.html')
library(datasets)
url <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
# almacenamiento de datos en dataframe
# los datos contienen información de la GEIH 2018 para Bogotá
data <- data.frame()
for (i in 1:10) {
url_i <- paste0(url, i, ".html")
tablas <- url_i %>%
read_html() %>%
html_table() %>% .[[1]]
data <- rbind.data.frame(data, tablas)
}
p_load(
tidyverse,
rvest,
writexl
)
library(tidyverse)
library(pacman)
library(rvest)
library(data.table)
library(datasets)
Chunk6 <-read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_6.html')
class(Chunk6)
Chunk6 <- my_htlm ("https://ignaciomsarmiento.github.io/GEIH2018_sample/page6.html")
load("~/Library/CloudStorage/OneDrive-UniversidaddelosAndes/2023/2023-1/BIG DATA/TALLERES GRUPALES/TALLER No. 1/GIT/Prblem_Set_1/2. SCRIPTS/Scraping_6_10.R")
p_load(
tidyverse,
rvest.
writeexl
p_load(
tidyverse,
rvest.
writexl
p_load(
tidyverse,
rvestl,
writexl
)
library(pacman)
p_load(tidyverse,rvest,writexl)
library(pacman)
p_load(tidyverse,rvest,writexl)
library(data.table)
library(datasets)
library(pacman)
p_load(tidyverse,rvest,writexl)
library(data.table)
library(datasets)
url <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
# almacenamiento de datos en dataframe
# los datos contienen información de la GEIH 2018 para Bogotá
data <- data.frame()
for (i in 1:10) {
url_i <- paste0(url, i, ".html")
tablas <- url_i %>%
read_html() %>%
html_table() %>% .[[1]]
data <- rbind.data.frame(data, tablas)
}
for (i in 1:10)
url <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
Chunk6 <- read_html(https://ignaciomsarmiento.github.io/GEIH2018_sample/page6.html)
Chunk6 <- read_html(https://ignaciomsarmiento.github.io/GEIH2018_sample/page6.html)
Chunk6 <- read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_6.html')
view(data)
#Scraping de los datos
## Datos de Chunks 6-10
### Carlos, Danna, Héctor, Alexa
#Se prepara el espacio por medio del llamado a los paquetes y librerías:
library(pacman)
p_load(tidyverse,rvest,writexl)
library(data.table)
library(datasets)
#Se realiza el scraping de los Chunks 6 a 10:
url <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
data <- data.frame()
for (i in 6:10) {
url_i <- paste0(url, i, ".html")
tablas <- url_i %>%
read_html() %>%
html_table() %>% .[[1]]
data <- rbind.data.frame(data, tablas)
}
view(data)
library(pacman)
p_load(tidyverse,rvest,writexl)
library(data.table)
library(datasets)
#Se realiza el scraping de los Chunks 6 a 10:
url <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
data <- data.frame()
for (i in 6:10) {
url_i <- paste6(url, i, ".html")
tablas <- url_i %>%
read_html() %>%
html_table() %>% .[[1]]
data <- rbind.data.frame(data, tablas)
}
colname(data)[1] <- "CC"
colnames(data)[1] <- "CC"
colnames(data)[1] <- "a"
colnames(data)[1] <- "n"
View(data)
View(data)
library(pacman)
p_load(tidyverse,rvest,writexl)
library(data.table)
library(datasets)
#Se realiza el scraping de los Chunks 6 a 10:
url <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
data <- data.frame()
for (i in 6:10) {
url_i <- paste0(url, i, ".html")
tablas <- url_i %>%
read_html() %>%
html_table() %>% .[[1]]
data <- rbind.data.frame(data, tablas)
}
view(data)
data1 <- as_tible(data)
data1 <- as_tibble(data)
colnames(data) [1] <- "cc"
data1 <- as_tibble(data)
View(data1)
View(data1)
data1<-(data)[-1]
View(data1)
data2 <- as_tibble(data1)
View(data2)
saveRDS(data2, file = "data2,rds")
View(data2)
#Scraping de los datos
## Datos de Chunks 6-10
### Carlos, Danna, Héctor, Alexa
#Se prepara el espacio por medio del llamado a los paquetes y librerías:
library(pacman)
p_load(tidyverse,rvest,writexl)
library(data.table)
library(datasets)
#Se realiza el scraping de los Chunks 6 a 10:
url <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
data <- data.frame()
for (i in 1:10) {
url_i <- paste0(url, i, ".html")
tablas <- url_i %>%
read_html() %>%
html_table() %>% .[[1]]
data <- rbind.data.frame(data, tablas)
}
view(data)
data1<-(data)[-1]
data2 <- as_tibble(data1)
saveRDS(data2, file = "data2,rds")
##url
urldata <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/dictionary.html"
###--- 4. base de datos final ---###
tabla_des <- urldata %>% read_html() %>% html_table()
view(tabla_des)
write_xlsx(tabla_des, "tabla_descripcion.xlsx")
#Scraping de los datos
## Datos de Chunks 6-10
### Carlos, Danna, Héctor, Alexa
#Se prepara el espacio por medio del llamado a los paquetes y librerías:
library(pacman)
p_load("tidyverse","rvest","writexl","stargazer","ggplot2","reshape2", "dplyr","datasets", "skimr","gridExtra")
library(data.table)
#Se realiza el scraping de los Chunks 6 a 10:
url <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
data <- data.frame()
for (i in 1:10) {
url_i <- paste0(url, i, ".html")
tablas <- url_i %>%
read_html() %>%
html_table() %>% .[[1]]
data <- rbind.data.frame(data, tablas)
}
#Eliminamos la primera columna, la cual es de indices y no se requiere
data<-(data)[-1]
#Se transforma a tipo Tibble para un mejor análisis
Base_datos_final <- as_tibble(data)
#TENGO DUDA SI ESTO VA AQUI, DADO QUE NO SE NECESITA EXPORTAR LA BASE DE DATOS
saveRDS(Base_datos_final, file = "Base_datos_final.rds")
View(tablas)
View(tablas)
View(Base_datos_final)
stargazer(mod3, type="text")
df_sin_atipicos<-(df %>% filter(y_ingLab_m_ha <= limite_punto1))
df_anes <- na.omit(df_sin_atipicos[c("y_ingLab_m_ha","age")])
